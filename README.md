# 云影猎蛛者-基于Grounding DINO的端云协同射击六足机器人
![image](https://github.com/user-attachments/assets/90377063-cfa7-491c-842c-ccc0a36b71c6)
这篇参考文档写的比较随意，没技术报告里面那么多漂亮话，更多的实际开发调试中总结的经验，语言会比较朴素。
## 设计初衷
一开始只是想简单做个基于YOLO检测+PID控制的射击云台配合一辆小车。后面觉得吃技术老本还是太LOW了，想玩一玩最近比较火的多模态大模型，顺便再把老学长传承的六足机器人给用上，自此，便有了此项目。

一开始在考虑射击的时候，在思考能不能不仅仅就射人，而是我啥都能射，指哪打哪。考虑到应用场景和应用任务可以很复杂，要把各种各样的数据都考虑到，太麻烦了。因此想选择一些具有泛化性、零样本训练的模型。例如很火的Clip模型，不过之前在RDK-X5上也体验过clip模型，只能做到简单的分类，而并非目标检测，所以就继续实验一些视觉大模型。

在使用LLAMA Factory体验了一些视觉大模型后，例如QwenVL2.5，感觉输出的效率还是太慢了，而且每次都需要对大模型的回答进行解析处理，那样效率太低了。在不懈努力下，发现Grounding DINO模型，它是一种文本+图像的双模态模型。在输入文本提示词后，检测图像后直接输出检测框信息，单640*480图像在服务器4080super的单卡上最快可以跑到200ms，相比于其他大模型来说简直快到飞起。因此整个项目都基于该模型作为主体，包括后面的三级级联和端云协同方案。

至于为什么是六足机器人而不是四足机器人，原因有三：一方面是因为现在机器狗做的太火了，成本也比较高。另一方面是因为足数越少，姿态控制越难，机器狗的动作姿态啥的还需要调参，工作量太大。六足冗余度高，走路姿态随便控制就能保持平衡。最后是因为这个六足是老学长传承的，零成本（其实这才是主要原因）
## 功能介绍
整个机器人的功能需要实现自动跟踪射击、机器人移动、网页端远程操控。
前两个功能可以理解，但是为啥是网页端，主要是因为一开始是想做纯嵌入式端的语音控制，加个麦克风，连个讯飞大模型的事，后来考虑了一下应用场景，执行射击任务时应当是不能发出巨大声响的（虽然射击声音和舵机驱动声音已经够大了），至少不能大声密谋吧。所以就改做网页端了，相当于一个远程操控手能实时观测。
## 整体方案设计 

### Grounding DINO模型介绍

### 自适应像素-角度数学映射模型

### 机体控制逻辑

### 网络设计

### 网页界面设计

### 硬件设计

## 实验效果

## 代码结构

## 代码使用配置指令
